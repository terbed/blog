{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Understanding weighted Cross Entropy loss and its effects"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "__Problem description:__\n",
    "- we have a multiclass classification problem\n",
    "- the class imbalance is very large -> loss class weights are applied\n",
    "- in inference time the occurrence of a class (debris) is large  -> we want to classify rare classes in \"large noise\"\n",
    "- the rare classes have large amount of false positive predictions from the numerous debris class -> we should punish this during training\n",
    "\n",
    "cross entropy loss:\n",
    "$$ - \\sum_{c=1}^{N}y_c \\log(p_c)$$\n",
    "where N is the number of classes and c iterates through each class; $y$ is a binary label $[0, 1]$ and $p$ is the predicted class probability. We can create a probability value for each class with the application of softmax function:\n",
    "\n",
    "$$ p_i = \\frac{e^{x_i}}{\\sum_{c=1}^{N}e^{x_c}} $$\n",
    "This function exponentially highlights the class with the largest assigned value and suppresses the other ones. At this point, information from the predictions for the other classes appear in the calculated probability value. If there was a high value assigned to another class that will suppress the current class probability.\n",
    "\n",
    "If we have an imbalanced dataset we can apply class weights to correct the bias:\n",
    "$$ - \\sum_{c=1}^{N} w_c y_c \\log(p_c)$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that using LogSoftmax in the output layer and NLLLoss (negative log likelihood loss) is equivalent with  cross entropy loss.\n",
    "The output layer of the NN is LogSoftmax:\n",
    "$$ LogSoftmax(x) = log \\frac{e^{x_c}}{\\sum_{c=1}^{N} e^{x_c}} \\in [- \\inf, 0] $$\n",
    "\n",
    "where $x \\in \\mathcal{R}^{N}$ is the raw output of the NN; N is the number of classes.\n",
    "\n",
    "$$ NLLLoss(x) = -\\sum_{c=1}^{N}y_c x_c $$\n",
    "\n",
    "for the sake of simplicity we will stick to the cross entropy formulation (although our implementation use this scheme)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have 4 classes with the following sample distribution and assigned weights:\n",
    "\n",
    "- class1 (260) -> 0.8\n",
    "- class2 (10) -> 26\n",
    "- class3 (56) -> 4\n",
    "- class4 (500)-> 0.4\n",
    "\n",
    "The first 3 classes are rare objects and the fourth is the numerous debris class."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class_weights = np.array([0.8, 26, 4, 0.4])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# softmax\n",
    "def softmax(x: np.array):\n",
    "    return np.exp(x)/np.sum(np.exp(x))\n",
    "\n",
    "# CrossEntropyLoss\n",
    "def cross_entropy_loss(p: np.array, y: int, w: np.array):\n",
    "    \"\"\"\n",
    "    :param p: class probabilities\n",
    "    :param y: ground truth class index\n",
    "    :param w: class weights\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return -1 * np.log(p[y]) * w[y]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.99849499e-01 5.01671307e-05 5.01671307e-05 5.01671307e-05]\n",
      "0.00012041017484880806\n"
     ]
    }
   ],
   "source": [
    "# case 1\n",
    "# class 1 predicted correctly with large confidence\n",
    "y = 0\n",
    "x = [10, 0.1, 0.1, 0.1]\n",
    "p = softmax(x)\n",
    "l = cross_entropy_loss(p, y, class_weights)\n",
    "print(p)\n",
    "print(l)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(p)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.01671307e-05 9.99849499e-01 5.01671307e-05 5.01671307e-05]\n",
      "0.003913330682586261\n"
     ]
    }
   ],
   "source": [
    "# case 2\n",
    "# class 2 predicted correctly with large confidence\n",
    "y = 1\n",
    "x = [0.10, 10, 0.1, 0.1]\n",
    "p = softmax(x)\n",
    "l = cross_entropy_loss(p, y, class_weights)\n",
    "print(p)\n",
    "print(l)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.01671307e-05 5.01671307e-05 9.99849499e-01 5.01671307e-05]\n",
      "0.0006020508742440402\n"
     ]
    }
   ],
   "source": [
    "# case 3\n",
    "# class 3 predicted correctly with large confidence\n",
    "y = 2\n",
    "x = [0.10, 0.10, 10, 0.1]\n",
    "p = softmax(x)\n",
    "l = cross_entropy_loss(p, y, class_weights)\n",
    "print(p)\n",
    "print(l)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.01671307e-05 5.01671307e-05 5.01671307e-05 9.99849499e-01]\n",
      "6.020508742440403e-05\n"
     ]
    }
   ],
   "source": [
    "# case 4\n",
    "# class 4 predicted correctly with large confidence\n",
    "y = 3\n",
    "x = [0.10, 0.10, 0.10, 10]\n",
    "p = softmax(x)\n",
    "l = cross_entropy_loss(p, y, class_weights)\n",
    "print(p)\n",
    "print(l)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The trivial cases are clear: for a rare class a larger weight is assigned -> the network update for that class is scarce but its extent is large."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.80719233e-01 1.19192387e-01 4.41898075e-05 4.41898075e-05]\n",
      "0.10161311565097696\n"
     ]
    }
   ],
   "source": [
    "# class 1 predicted correctly with smaller confidence\n",
    "y = 0   # GT\n",
    "x = [10, 8, 0.1, 0.1]   # Network raw output\n",
    "p = softmax(x)\n",
    "l = cross_entropy_loss(p, y, class_weights)\n",
    "print(p)\n",
    "print(l)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.99798652e-01 5.01645795e-05 5.01645795e-05 1.01019058e-04]\n",
      "0.00016109479196323826\n"
     ]
    }
   ],
   "source": [
    "y = 0   # GT\n",
    "x = [10, 0.1, 0.1, 0.8]   # Network raw output\n",
    "p = softmax(x)\n",
    "l = cross_entropy_loss(p, y, class_weights)\n",
    "print(p)\n",
    "print(l)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.75562129e-01 1.18494449e-01 5.89949122e-03 4.39310514e-05]\n",
      "0.10631133259521273\n"
     ]
    }
   ],
   "source": [
    "y = 0   # GT\n",
    "x = [10, 8, 5, 0.1]   # Network raw output\n",
    "p = softmax(x)\n",
    "l = cross_entropy_loss(p, y, class_weights)\n",
    "print(p)\n",
    "print(l)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87046507 0.11780464 0.00586515 0.00586515]\n",
      "0.11098211900127541\n"
     ]
    }
   ],
   "source": [
    "x = [10, 8, 5, 5]   # Network raw output\n",
    "p = softmax(x)\n",
    "l = cross_entropy_loss(p, y, class_weights)\n",
    "print(p)\n",
    "print(l)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47536689 0.1748777  0.1748777  0.1748777 ]\n",
      "0.5949347045029433\n"
     ]
    }
   ],
   "source": [
    "x = [10, 9, 9, 9]   # Network raw output\n",
    "p = softmax(x)\n",
    "l = cross_entropy_loss(p, y, class_weights)\n",
    "print(p)\n",
    "print(l)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The critical case for us is when a debris is classified to an another class."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.93208148e-01 4.98339031e-05 4.98339031e-05 6.69218386e-03]\n",
      "2.0027260085049603\n"
     ]
    }
   ],
   "source": [
    "y = 3\n",
    "x = [10, 0.1, 0.1, 5]   # Network raw output\n",
    "p = softmax(x)\n",
    "l = cross_entropy_loss(p, y, class_weights)\n",
    "print(p)\n",
    "print(l)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.99849499e-01 5.01671307e-05 5.01671307e-05 5.01671307e-05]\n",
      "3.9600602050874247\n"
     ]
    }
   ],
   "source": [
    "x = [10, 0.1, 0.1, 0.1]   # Network raw output\n",
    "p = softmax(x)\n",
    "l = cross_entropy_loss(p, y, class_weights)\n",
    "print(p)\n",
    "print(l)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ideas\n",
    "\n",
    "To increase the punishment when a debris is wrongly classified we could play with the assigned weights.\n",
    "We could change the weights generated from the sample distribution to a custom value."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.99849499e-01 5.01671307e-05 5.01671307e-05 5.01671307e-05]\n",
      "9.900150512718561\n"
     ]
    }
   ],
   "source": [
    "class_weights[3] = 1\n",
    "\n",
    "x = [10, 0.1, 0.1, 0.1]   # Network raw output\n",
    "p = softmax(x)\n",
    "l = cross_entropy_loss(p, y, class_weights)\n",
    "print(p)\n",
    "print(l)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.99849499e-01 5.01671307e-05 5.01671307e-05 5.01671307e-05]\n",
      "7.9201204101748495\n"
     ]
    }
   ],
   "source": [
    "class_weights[3] = 0.8\n",
    "\n",
    "x = [10, 0.1, 0.1, 0.1]   # Network raw output\n",
    "p = softmax(x)\n",
    "l = cross_entropy_loss(p, y, class_weights)\n",
    "print(p)\n",
    "print(l)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The pitfalls of this is that the number of false negative predictions from the rare classes might increase, so it might tend to classify samples from rare class to the debris class.\n",
    "Thus, the weights must be carefully chosen."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
